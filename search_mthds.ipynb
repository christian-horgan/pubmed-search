{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Includes functions that are used to search and create a dataframe for PubMed articles based on their grant number\n",
    "#### Main program that references these functions is included in mainpgrm notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import lxml\n",
    "import xmltodict\n",
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get PubMed IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take in the grant number as a string, and return the PubMed article ids associated with that grant number\n",
    "#If no articles come up during the search, return none\n",
    "\n",
    "def returnIDs(grant_num):\n",
    "    rsp = requests.get(f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&retmode=json&term={grant_num}[Grant Number]')\n",
    "    info = rsp.json() #convert the information from the response into a json to make it easily accessible\n",
    "    ids = info['esearchresult']['idlist'] #grab the id list from the json information\n",
    "    if ids != []:\n",
    "        return ids #return id list\n",
    "    else:\n",
    "        return \"Nothing found\" #if there are no papers found, return Nothing found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Summary Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that takes in a list of PubMed Ids and returns the summary information for the articles associated with those IDs; returns a dictionary\n",
    "#Can use this function in conjunction with returnIDs() function to go from grant number to article summaries\n",
    "#The summary information includes a variety of information such as titles for all articles, authors, identifiers and more\n",
    "\n",
    "def get_summary(idList):\n",
    "    rsp = requests.get(f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=pubmed&retmode=json&id={','.join(idList)}\") #use join here to make list of ids into one comma separated string\n",
    "    info = rsp.json() #convert the response information to easily accessible json info\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that takes in the summary of all articles given by the ids and returns a dictionary with the title of each article\n",
    "\n",
    "def get_titles(summary):\n",
    "    uids = summary['result']['uids'] #gives the list of unique ids for all articles in the summary\n",
    "    title_dict = {}\n",
    "    for id in uids:\n",
    "        title_dict[id] = summary['result'][id]['title']\n",
    "        #This grabs the title, summary is the information retrieved by esummary, 'results' is the key for the paper's info\n",
    "        #within 'results' is each id and their corresponding info, within each id we can grab the info we want, in this case, the paper title\n",
    "    return title_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that takes in the summary of all the articles and returns a dictionary containing the authors of each article\n",
    "\n",
    "def get_authors(summary):\n",
    "    uids = summary['result']['uids'] #gives the list of unique ids\n",
    "    author_dict = {} #create an empty dictionary that will store the authors by pubmed id\n",
    "    for id in uids: #parse through each article given by the search via their ids\n",
    "        authors = summary['result'][id]['authors'] #this line accesses the authors list\n",
    "        auth_ls = [] #define an empty list where the author names will be kept\n",
    "        for author in authors: #append each author for the current article\n",
    "            auth_ls.append(author['name'])\n",
    "        author_dict[id] = auth_ls\n",
    "    return author_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get DOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that takes in the summary of all the articles and returns a dictioanry containing the doi of each article\n",
    "\n",
    "def get_DOI(summary):\n",
    "    uids = summary['result']['uids'] #gives the list of unique ids\n",
    "    doi_dict = {}\n",
    "    for id in uids:\n",
    "        doi_dict[id] = summary['result'][id]['elocationid'] #grab the identifier from the list of information, place it into a dictionary\n",
    "    return doi_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that takes in a list of PubMed IDs, gets a batch of information from PubMed that includes information about the articles for those IDs\n",
    "#efetch API is used to grab article information, converts the information into a beautiful soup object, and then it parses through\n",
    "#the article information to get the keywords for each article\n",
    "\n",
    "def get_keywords(idList): \n",
    "    rsp = requests.get(f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&retmode=xml&id={','.join(idList)}\")\n",
    "    articles_bs = BeautifulSoup(rsp.content, features = 'xml') #create a beautiful soup object out of the response, this will hold all information for the articles\n",
    "    articles_iterable = articles_bs.find_all('PubmedArticle') #Creates an iterable for all of the articles in the ID list\n",
    "    keyword_dict = {}\n",
    "    for article in articles_iterable: #parse through each 'PubmedArticle' tag (each article in the search)\n",
    "        id = article.find('PMID').text #grab the pubmed id for the current article\n",
    "        keywordList = article.find_all('Keyword') #get the keywords for the current article\n",
    "        new_keywords = [x.text for x in keywordList] #convert the keyword tags into text/a list of strings\n",
    "        if keywordList == []: #accounts for articles with no keywords\n",
    "            keyword_dict[id] = 'No keywords'\n",
    "        else:\n",
    "            keyword_dict[id] = new_keywords\n",
    "    return keyword_dict\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
